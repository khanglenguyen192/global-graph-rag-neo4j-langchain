{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"12345678\"\n",
    "\n",
    "graph = Neo4jGraph(refresh_schema=False)    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hàm đếm tokens\n",
    "def num_tokens_from_string(string: str, model_name: str = \"gpt-3.5-turbo\") -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    return len(encoding.encode(string))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b1178dbfc621671"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tiktoken\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from graphdatascience import GraphDataScience\n",
    "\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_community.vectorstores.neo4j_vector import (\n",
    "    Neo4jVector,\n",
    "    remove_lucene_chars,\n",
    ")\n",
    "\n",
    "from neo4j import Result\n",
    "from typing import Dict, Any"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5225ec0c680b9c53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"API-KEY-HERE\"\n",
    "\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1067775abb141075"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "  llm=llm, \n",
    "  node_properties=[\"description\"],\n",
    "  relationship_properties=[\"description\"]\n",
    ")\n",
    "\n",
    "def process_text(text: str) -> List[Document]:\n",
    "    doc = Document(page_content=text)\n",
    "    return llm_transformer.convert_to_graph_documents([doc])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c5bb6d64bd2ab49"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test\n",
    "sample_text = \"\"\n",
    "with open(\"data/sample_text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sample_text = f.read()\n",
    "\n",
    "sample_doc = process_text(text=sample_text)\n",
    "\n",
    "print(sample_doc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2211b8c80be6702a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph.add_graph_documents(\n",
    "    sample_doc,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91f23b5f1065faae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for i in range(1, 64):\n",
    "    chunkDoc = \"\"\n",
    "    chunkFileName = \"p\" + str(i) + \".txt\"\n",
    "    with open(\"data/quydinhdaotaothacsi/\" + chunkFileName, \"r\", encoding=\"utf-8\") as f:\n",
    "        chunkDoc = f.read()\n",
    "    documents.append(chunkDoc)    \n",
    "    chunkDocProcessed = process_text(text=chunkDoc)\n",
    "    graph.add_graph_documents(\n",
    "    chunkDocProcessed,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")\n",
    "    \n",
    "print(len(documents))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dad14b4ab16add7d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MAX_WORKERS = 2\n",
    "NUM_CHUNK = 63\n",
    "\n",
    "def process_chunk_file(i):\n",
    "    chunkFileName = f\"p{i}.txt\"\n",
    "    file_path = f\"data/quydinhdaotaothacsi/{chunkFileName}\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        chunkDoc = f.read()\n",
    "    return process_text(text=chunkDoc)\n",
    "\n",
    "graph_documents = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = [\n",
    "        executor.submit(process_chunk_file, i)\n",
    "        for i in range(1, NUM_CHUNK + 1)\n",
    "    ]\n",
    "\n",
    "    for future in tqdm(\n",
    "        as_completed(futures), total=len(futures), desc=\"Processing documents\"\n",
    "    ):\n",
    "        chunkDocProcessed = future.result()\n",
    "        graph_documents.extend(chunkDocProcessed)\n",
    "\n",
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5661544d9586edc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "entity_dist = graph.query(\n",
    "    \"\"\"\n",
    "MATCH (d:Document)\n",
    "RETURN d.text AS text,\n",
    "       count {(d)-[:MENTIONS]->()} AS entity_count\n",
    "\"\"\"\n",
    ")\n",
    "entity_dist_df = pd.DataFrame.from_records(entity_dist)\n",
    "entity_dist_df[\"token_count\"] = [\n",
    "    num_tokens_from_string(str(el)) for el in entity_dist_df[\"text\"]\n",
    "]\n",
    "# Scatter plot with regression line\n",
    "sns.lmplot(\n",
    "    x=\"token_count\",\n",
    "    y=\"entity_count\",\n",
    "    data=entity_dist_df, \n",
    "    line_kws={\"color\": \"red\"}\n",
    ")\n",
    "plt.title(\"Entity Count vs Token Count Distribution\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Entity Count\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5943792bb7c1731d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "degree_dist = graph.query(\n",
    "    \"\"\"\n",
    "MATCH (e:__Entity__)\n",
    "RETURN count {(e)-[:!MENTIONS]-()} AS node_degree\n",
    "\"\"\"\n",
    ")\n",
    "degree_dist_df = pd.DataFrame.from_records(degree_dist)\n",
    "\n",
    "# Calculate mean and median\n",
    "mean_degree = np.mean(degree_dist_df['node_degree'])\n",
    "percentiles = np.percentile(degree_dist_df['node_degree'], [25, 50, 75, 90])\n",
    "# Create a histogram with a logarithmic scale\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(degree_dist_df['node_degree'], bins=50, kde=False, color='blue')\n",
    "# Use a logarithmic scale for the x-axis\n",
    "plt.yscale('log')\n",
    "# Adding labels and title\n",
    "plt.xlabel('Node Degree')\n",
    "plt.ylabel('Count (log scale)')\n",
    "plt.title('Node Degree Distribution')\n",
    "# Add mean, median, and percentile lines\n",
    "plt.axvline(mean_degree, color='red', linestyle='dashed', linewidth=1, label=f'Mean: {mean_degree:.2f}')\n",
    "plt.axvline(percentiles[0], color='purple', linestyle='dashed', linewidth=1, label=f'25th Percentile: {percentiles[0]:.2f}')\n",
    "plt.axvline(percentiles[1], color='orange', linestyle='dashed', linewidth=1, label=f'50th Percentile: {percentiles[1]:.2f}')\n",
    "plt.axvline(percentiles[2], color='yellow', linestyle='dashed', linewidth=1, label=f'75th Percentile: {percentiles[2]:.2f}')\n",
    "plt.axvline(percentiles[3], color='brown', linestyle='dashed', linewidth=1, label=f'90th Percentile: {percentiles[3]:.2f}')\n",
    "# Add legend\n",
    "plt.legend()\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d02efb336f851c37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph.query(\"\"\"\n",
    "MATCH (n:`__Entity__`)\n",
    "RETURN \"node\" AS type,\n",
    "       count(*) AS total_count,\n",
    "       count(n.description) AS non_null_descriptions\n",
    "UNION ALL\n",
    "MATCH (n)-[r:!MENTIONS]->()\n",
    "RETURN \"relationship\" AS type,\n",
    "       count(*) AS total_count,\n",
    "       count(r.description) AS non_null_descriptions\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab765760d223e34"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### De-duplication"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5ab31085cf8cdc0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vector = Neo4jVector.from_existing_graph(\n",
    "    OpenAIEmbeddings(),\n",
    "    node_label='__Entity__',\n",
    "    text_node_properties=['id', 'description'],\n",
    "    embedding_node_property='embedding'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69ee8ef7d00cc262"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gds = GraphDataScience(\n",
    "    os.environ[\"NEO4J_URI\"],\n",
    "    auth=(os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb392785167b6693"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "G, result = gds.graph.project(\n",
    "    \"entities\",                   # Graph name\n",
    "    \"__Entity__\",                 # Node projection\n",
    "    \"*\",                          # Relationship projection\n",
    "    nodeProperties=[\"embedding\"]  # Configuration parameters\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66f674512235c498"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "similarity_threshold = 0.95\n",
    "\n",
    "gds.knn.mutate(\n",
    "  G,\n",
    "  nodeProperties=['embedding'],\n",
    "  mutateRelationshipType= 'SIMILAR',\n",
    "  mutateProperty= 'score',\n",
    "  similarityCutoff=similarity_threshold\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79c30669ec64e650"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gds.wcc.write(\n",
    "    G,\n",
    "    writeProperty=\"wcc\",\n",
    "    relationshipTypes=[\"SIMILAR\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c2ab11389a3b6a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_edit_distance = 3\n",
    "potential_duplicate_candidates = graph.query(\n",
    "    \"\"\"MATCH (e:`__Entity__`)\n",
    "    WHERE size(e.id) > 3 // longer than 3 characters\n",
    "    WITH e.wcc AS community, collect(e) AS nodes, count(*) AS count\n",
    "    WHERE count > 1\n",
    "    UNWIND nodes AS node\n",
    "    // Add text distance\n",
    "    WITH distinct\n",
    "      [n IN nodes WHERE apoc.text.distance(toLower(node.id), toLower(n.id)) < $distance \n",
    "                  OR node.id CONTAINS n.id | n.id] AS intermediate_results\n",
    "    WHERE size(intermediate_results) > 1\n",
    "    WITH collect(intermediate_results) AS results\n",
    "    // combine groups together if they share elements\n",
    "    UNWIND range(0, size(results)-1, 1) as index\n",
    "    WITH results, index, results[index] as result\n",
    "    WITH apoc.coll.sort(reduce(acc = result, index2 IN range(0, size(results)-1, 1) |\n",
    "            CASE WHEN index <> index2 AND\n",
    "                size(apoc.coll.intersection(acc, results[index2])) > 0\n",
    "                THEN apoc.coll.union(acc, results[index2])\n",
    "                ELSE acc\n",
    "            END\n",
    "    )) as combinedResult\n",
    "    WITH distinct(combinedResult) as combinedResult\n",
    "    // extra filtering\n",
    "    WITH collect(combinedResult) as allCombinedResults\n",
    "    UNWIND range(0, size(allCombinedResults)-1, 1) as combinedResultIndex\n",
    "    WITH allCombinedResults[combinedResultIndex] as combinedResult, combinedResultIndex, allCombinedResults\n",
    "    WHERE NOT any(x IN range(0,size(allCombinedResults)-1,1)\n",
    "        WHERE x <> combinedResultIndex\n",
    "        AND apoc.coll.containsAll(allCombinedResults[x], combinedResult)\n",
    "    )\n",
    "    RETURN combinedResult\n",
    "    \"\"\", params={'distance': word_edit_distance})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae41acfc7c699c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Xác định các thực thể trùng lặp trong danh sách và quyết định thực thể nào trong số chúng nên được hợp nhất.\n",
    "Các thực thể có thể hơi khác nhau về định dạng hoặc nội dung, nhưng về cơ bản đều đề cập đến cùng một thứ. Sử dụng các kỹ năng phân tích của bạn để xác định các bản sao.\n",
    "\n",
    "Sau đây là các quy tắc để xác định các bản sao:\n",
    "1. Các thực thể có sự khác biệt nhỏ về kiểu chữ nên được coi là bản sao.\n",
    "2. Các thực thể có định dạng khác nhau nhưng cùng nội dung nên được coi là bản sao.\n",
    "3. Các thực thể đề cập đến cùng một đối tượng hoặc khái niệm trong thế giới thực, ngay cả khi được mô tả khác nhau, nên được coi là bản sao.\n",
    "4. Nếu nó đề cập đến các số, ngày hoặc sản phẩm khác nhau, thì không được hợp nhất kết quả\n",
    "\"\"\"\n",
    "user_template = \"\"\"\n",
    "Dưới đây là danh sách các thực thể cần xử lý:\n",
    "{entities}\n",
    "\n",
    "Xác định các mục trùng lặp, hợp nhất chúng và cung cấp danh sách đã hợp nhất.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e513c43b9a52d7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DuplicateEntities(BaseModel):\n",
    "    entities: List[str] = Field(\n",
    "        description=\"Các thực thể đại diện cho cùng một đối tượng hoặc thực thể trong thế giới thực và cần được hợp nhất\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Disambiguate(BaseModel):\n",
    "    merge_entities: Optional[List[DuplicateEntities]] = Field(\n",
    "        description=\"Danh sách các thực thể đại diện cho cùng một đối tượng hoặc thực thể trong thế giới thực và cần được hợp nhất\"\n",
    "    )\n",
    "\n",
    "\n",
    "extraction_llm = ChatOpenAI(model_name=\"gpt-4o\").with_structured_output(\n",
    "    Disambiguate\n",
    ")\n",
    "\n",
    "extraction_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_prompt,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            user_template,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "579614d75cdff598"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extraction_chain = extraction_prompt | extraction_llm\n",
    "\n",
    "def entity_resolution(entities: List[str]) -> Optional[List[List[str]]]:\n",
    "    return [\n",
    "        el.entities\n",
    "        for el in extraction_chain.invoke({\"entities\": entities}).merge_entities\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f78c1955ee2c9c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_entities = []\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    # Submitting all tasks and creating a list of future objects\n",
    "    futures = [\n",
    "        executor.submit(entity_resolution, el['combinedResult'])\n",
    "        for el in potential_duplicate_candidates\n",
    "    ]\n",
    "\n",
    "    for future in tqdm(\n",
    "        as_completed(futures), total=len(futures), desc=\"Processing documents\"\n",
    "    ):\n",
    "        to_merge = future.result()\n",
    "        if to_merge is not None:\n",
    "            merged_entities.extend(to_merge)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ad8ba7aa0622e81"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(merged_entities)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1094f89645393a7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph.query(\"\"\"\n",
    "UNWIND $data AS candidates\n",
    "CALL {\n",
    "  WITH candidates\n",
    "  MATCH (e:__Entity__) WHERE e.id IN candidates\n",
    "  RETURN collect(e) AS nodes\n",
    "}\n",
    "CALL apoc.refactor.mergeNodes(nodes, {properties: {\n",
    "    description:'combine',\n",
    "    `.*`: 'discard'\n",
    "}})\n",
    "YIELD node\n",
    "RETURN count(*)\n",
    "\"\"\", params={\"data\": merged_entities})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9e925ae79092d1d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Constructing and Summarizing Communities"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7126832d5009d90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "G, result = gds.graph.project(\n",
    "    \"communities\",  #  Graph name\n",
    "    \"__Entity__\",  #  Node projection\n",
    "    {\n",
    "        \"_ALL_\": {\n",
    "            \"type\": \"*\",\n",
    "            \"orientation\": \"UNDIRECTED\",\n",
    "            \"properties\": {\"weight\": {\"property\": \"*\", \"aggregation\": \"COUNT\"}},\n",
    "        }\n",
    "    },\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e30b9abe0a6af3b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wcc = gds.wcc.stats(G)\n",
    "print(f\"Component count: {wcc['componentCount']}\")\n",
    "print(f\"Component distribution: {wcc['componentDistribution']}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "453cb63b2e7fb022"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gds.leiden.write(\n",
    "    G,\n",
    "    writeProperty=\"communities\",\n",
    "    includeIntermediateCommunities=True,\n",
    "    relationshipWeightProperty=\"weight\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bee38996a601c41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph.query(\"\"\"\n",
    "MATCH (e:`__Entity__`)\n",
    "UNWIND range(0, size(e.communities) - 1 , 1) AS index\n",
    "CALL {\n",
    "  WITH e, index\n",
    "  WITH e, index\n",
    "  WHERE index = 0\n",
    "  MERGE (c:`__Community__` {id: toString(index) + '-' + toString(e.communities[index])})\n",
    "  ON CREATE SET c.level = index\n",
    "  MERGE (e)-[:IN_COMMUNITY]->(c)\n",
    "  RETURN count(*) AS count_0\n",
    "}\n",
    "CALL {\n",
    "  WITH e, index\n",
    "  WITH e, index\n",
    "  WHERE index > 0\n",
    "  MERGE (current:`__Community__` {id: toString(index) + '-' + toString(e.communities[index])})\n",
    "  ON CREATE SET current.level = index\n",
    "  MERGE (previous:`__Community__` {id: toString(index - 1) + '-' + toString(e.communities[index - 1])})\n",
    "  ON CREATE SET previous.level = index - 1\n",
    "  MERGE (previous)-[:IN_COMMUNITY]->(current)\n",
    "  RETURN count(*) AS count_1\n",
    "}\n",
    "RETURN count(*)\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae2fd9f3e289a032"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph.query(\"\"\"\n",
    "MATCH (c:__Community__)<-[:IN_COMMUNITY*]-(:__Entity__)<-[:MENTIONS]-(d:Document)\n",
    "WITH c, count(distinct d) AS rank\n",
    "SET c.community_rank = rank;\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd4f2fab60df303"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "community_size = graph.query(\n",
    "    \"\"\"\n",
    "MATCH (c:__Community__)<-[:IN_COMMUNITY*]-(e:__Entity__)\n",
    "WITH c, count(distinct e) AS entities\n",
    "RETURN split(c.id, '-')[0] AS level, entities\n",
    "\"\"\"\n",
    ")\n",
    "community_size_df = pd.DataFrame.from_records(community_size)\n",
    "percentiles_data = []\n",
    "for level in community_size_df[\"level\"].unique():\n",
    "    subset = community_size_df[community_size_df[\"level\"] == level][\"entities\"]\n",
    "    num_communities = len(subset)\n",
    "    percentiles = np.percentile(subset, [25, 50, 75, 90, 99])\n",
    "    percentiles_data.append(\n",
    "        [\n",
    "            level,\n",
    "            num_communities,\n",
    "            percentiles[0],\n",
    "            percentiles[1],\n",
    "            percentiles[2],\n",
    "            percentiles[3],\n",
    "            percentiles[4],\n",
    "            max(subset)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Create a DataFrame with the percentiles\n",
    "percentiles_df = pd.DataFrame(\n",
    "    percentiles_data,\n",
    "    columns=[\n",
    "        \"Level\",\n",
    "        \"Number of communities\",\n",
    "        \"25th Percentile\",\n",
    "        \"50th Percentile\",\n",
    "        \"75th Percentile\",\n",
    "        \"90th Percentile\",\n",
    "        \"99th Percentile\",\n",
    "        \"Max\"\n",
    "    ],\n",
    ")\n",
    "percentiles_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e01fceacb626e70c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "community_info = graph.query(\"\"\"\n",
    "MATCH (c:`__Community__`)<-[:IN_COMMUNITY*]-(e:__Entity__)\n",
    "WHERE c.level IN [0,1,4]\n",
    "WITH c, collect(e ) AS nodes\n",
    "WHERE size(nodes) > 1\n",
    "CALL apoc.path.subgraphAll(nodes[0], {\n",
    " whitelistNodes:nodes\n",
    "})\n",
    "YIELD relationships\n",
    "RETURN c.id AS communityId, \n",
    "       [n in nodes | {id: n.id, description: n.description, type: [el in labels(n) WHERE el <> '__Entity__'][0]}] AS nodes,\n",
    "       [r in relationships | {start: startNode(r).id, type: type(r), end: endNode(r).id, description: r.description}] AS rels\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a8fe6759325a2c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "community_template = \"\"\"Dựa trên các nút và mối quan hệ được cung cấp thuộc về cùng một cộng đồng đồ thị, tạo bản tóm tắt bằng ngôn ngữ tự nhiên về thông tin được cung cấp:\n",
    "{community_info}\n",
    "\n",
    "Tóm tăt:\"\"\"  # noqa: E501\n",
    "\n",
    "community_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Với một bộ ba đầu vào, tạo ra bản tóm tắt thông tin. Không có phần mở đầu.\",\n",
    "        ),\n",
    "        (\"human\", community_template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "community_chain = community_prompt | llm | StrOutputParser()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73e28703c245ba75"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_string(data):\n",
    "    nodes_str = \"Nodes are:n\"\n",
    "    for node in data['nodes']:\n",
    "        node_id = node['id']\n",
    "        node_type = node['type']\n",
    "        if 'description' in node and node['description']:\n",
    "            node_description = f\", description: {node['description']}\"\n",
    "        else:\n",
    "            node_description = \"\"\n",
    "        nodes_str += f\"id: {node_id}, type: {node_type}{node_description}n\"\n",
    "\n",
    "    rels_str = \"Relationships are:n\"\n",
    "    for rel in data['rels']:\n",
    "        start = rel['start']\n",
    "        end = rel['end']\n",
    "        rel_type = rel['type']\n",
    "        if 'description' in rel and rel['description']:\n",
    "            description = f\", description: {rel['description']}\"\n",
    "        else:\n",
    "            description = \"\"\n",
    "        rels_str += f\"({start})-[:{rel_type}]->({end}){description}n\"\n",
    "\n",
    "    return nodes_str + \"n\" + rels_str\n",
    "\n",
    "def process_community(community):\n",
    "    stringify_info = prepare_string(community)\n",
    "    summary = community_chain.invoke({'community_info': stringify_info})\n",
    "    return {\"community\": community['communityId'], \"summary\": summary}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6a35501304968e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summaries = []\n",
    "MAX_WORKERS = 2\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = {executor.submit(process_community, community): community for community in community_info}\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing communities\"):\n",
    "        summaries.append(future.result())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4966f22bc7b6f3b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(summaries)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e5ebcae11f95d82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph.query(\"\"\"\n",
    "UNWIND $data AS row\n",
    "MERGE (c:__Community__ {id:row.community})\n",
    "SET c.summary = row.summary\n",
    "\"\"\", params={\"data\": summaries})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "573d6a4743c070e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Local Retrieval"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c1db7f066865cb7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\n",
    "        uri = os.environ[\"NEO4J_URI\"],\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
    "                os.environ[\"NEO4J_PASSWORD\"]))\n",
    "\n",
    "def create_fulltext_index(tx):\n",
    "    query = '''\n",
    "    CREATE FULLTEXT INDEX `fulltext_entity_id` \n",
    "    FOR (n:__Entity__) \n",
    "    ON EACH [n.id];\n",
    "    '''\n",
    "    tx.run(query)\n",
    "\n",
    "# Function to execute the query\n",
    "def create_index():\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(create_fulltext_index)\n",
    "        print(\"Fulltext index created successfully.\")\n",
    "\n",
    "# Call the function to create the index\n",
    "try:\n",
    "    create_index()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Close the driver connection\n",
    "driver.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd051ba19e3658bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract entities from question"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73bc21a8c49d7f9a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"Tất cả các thực thể trong văn bản\",\n",
    "    )\n",
    "\n",
    "extract_entities_from_question_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Trích xuất thực thể từ văn bản.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Sử dụng định dạng đã cho để trích xuất thông tin các thực thể từ những nội dung sau, trả kết quả dưới dạng danh sách, nếu là một thực thể nhiều thông tin, hãy chia nhỏ ra \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "entity_chain = extract_entities_from_question_prompt | llm.with_structured_output(Entities)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "956f46b3c7b5a322"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Local query\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7604ef328d2dc2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BASE_LOCAL_QUERY = \"\"\"CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\"\n",
    "LOCAL_QUERY_WITH_DESSCRIPTION = \"\"\"\n",
    "            CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN\n",
    "                node.id + ' (desc: ' + coalesce(node.description, '') + ')' + ' - ' +\n",
    "                type(r) + ' -> ' +\n",
    "                neighbor.id + ' (desc: ' + coalesce(neighbor.description, '') + ')' AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN\n",
    "                neighbor.id + ' (desc: ' + coalesce(neighbor.description, '') + ')' + ' - ' +\n",
    "                type(r) + ' -> ' +\n",
    "                node.id + ' (desc: ' + coalesce(node.description, '') + ')' AS output\n",
    "            }\n",
    "            RETURN output LIMIT 100\n",
    "            \"\"\"\n",
    "\n",
    "LOCAL_QUERY_WITH_DESSCRIPTION_AND_SUMMARY = \"\"\"\n",
    "            CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\n",
    "            YIELD node, score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN\n",
    "                node.id + ' (desc: ' + coalesce(node.description, '') + ')' + ' - ' +\n",
    "                type(r) + ' -> ' +\n",
    "                neighbor.id + ' (desc: ' + coalesce(neighbor.description, neighbor.summary, '') + ')' AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN\n",
    "                neighbor.id + ' (desc: ' + coalesce(neighbor.description, neighbor.summary, '') + ')' + ' - ' +\n",
    "                type(r) + ' -> ' +\n",
    "                node.id + ' (desc: ' + coalesce(node.description, '') + ')' AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bea45957d6d597bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_full_text_query(input: str) -> str:\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    if not words:\n",
    "        return \"\"\n",
    "    full_text_query = \" AND \".join([f\"{word}~2\" for word in words])\n",
    "    print(f\"Generated Query: {full_text_query}\")\n",
    "    return full_text_query.strip()\n",
    "\n",
    "\n",
    "# Fulltext index query\n",
    "def graph_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Collects the neighborhood of entities mentioned\n",
    "    in the question\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke(question)\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            LOCAL_QUERY_WITH_DESSCRIPTION,\n",
    "            {\"query\": entity},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84c46241cd9fe243"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "entity_chain.invoke(\"Đăng ký môn học?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88acefe99cd2e323"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(graph_retriever(\"Điều kiện đăng ký môn học là gì?\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0ed8a57d3016d7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(graph_retriever(\"Thạc sĩ nghiên cứu cần có bài báo như thế nào để đủ điều kiện bảo vệ luận văn?\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "591d6f47a0f3e6af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(graph_retriever(\"Học viên có thể tạm dừng học bao lâu?\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "161b711cbfe2eb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sử dụng OpenAIEmbeddings\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")`\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "\n",
    "vector_retriever = vector_index.as_retriever()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4f11d06987f4b37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def full_retriever(question: str):\n",
    "    graph_data = graph_retriever(question)\n",
    "    vector_data = [el.page_content for el in vector_retriever.invoke(question)]\n",
    "    final_data = f\"\"\"Graph data:\n",
    "{graph_data}\n",
    "vector data:\n",
    "{\"#Document \". join(vector_data)}\n",
    "    \"\"\"\n",
    "    return final_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f461b2ebc847ccd2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "template = \"\"\"Trả lời câu hỏi dựa trên ngữ cảnh được cung cấp:\n",
    "{context}\n",
    "Thông tin trong desc là mô tả của thực thể trong ngữ cảnh. Có một số quan hệ được mô tả bằng tiếng Anh, hãy thêm chúng vào.\n",
    "Câu hỏi: {question}\n",
    "Sử dụng ngôn ngữ tự nhiên và trả lời ngắn gọn.\n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "        {\n",
    "            \"context\": full_retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59b31e07e9976e03"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chain.invoke(input=\"khi nào học viên bị cảnh cáo học vụ?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e7ca6339e34aca4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chain.invoke(input=\"Điều kiện đăng ký môn học là gì?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5d96dab1cf58f65"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chain.invoke(input=\"Học viên có thể tạm dừng học bao lâu?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff4a0af81dbdbace"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chain.invoke(input=\"Thạc sĩ nghiên cứu cần có bài báo như thế nào để đủ điều kiện bảo vệ luận văn?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f49db762fb82cec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Global Retrieval\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20d732c0a0246f0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def retrieve_from_community(question: str):\n",
    "    # 1. Trích thực thể\n",
    "    entities = entity_chain.invoke(question).names\n",
    "    if not entities:\n",
    "        return \"No entities found.\"\n",
    "\n",
    "    # 2. Tìm entity node + community\n",
    "    response = graph.query(\"\"\"\n",
    "    CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:1})\n",
    "    YIELD node RETURN node.id as entity_id\n",
    "    \"\"\", {\"query\": entities[0]})\n",
    "\n",
    "    if not response:\n",
    "        return \"Entity not found in graph.\"\n",
    "\n",
    "    entity_id = response[0]['entity_id']\n",
    "\n",
    "    # 3. Truy community id\n",
    "    community = graph.query(\"\"\"\n",
    "    MATCH (n:__Entity__)-[:__IN_COMMUNITY__]->(c:__Community__)\n",
    "    WHERE n.id = $entity_id\n",
    "    RETURN c.id as community_id\n",
    "    \"\"\", {\"entity_id\": entity_id})\n",
    "    if not community:\n",
    "        return \"No community found.\"\n",
    "\n",
    "    community_id = community[0]['community_id']\n",
    "\n",
    "    # 4. Lấy thông tin community\n",
    "    community_info = graph.query(\"\"\"\n",
    "    MATCH (e:__Entity__)-[:__IN_COMMUNITY__]->(:__Community__ {id: $community_id})\n",
    "    OPTIONAL MATCH (e)-[r]->(n)\n",
    "    RETURN e, r, n\n",
    "    \"\"\", {\"community_id\": community_id})\n",
    "\n",
    "    # 5. Format lại để feed vào prompt\n",
    "    community_text = format_community_info(community_info)\n",
    "\n",
    "    # 6. Tóm tắt\n",
    "    summary = community_chain.invoke({\"community_info\": community_text})\n",
    "\n",
    "    # 7. Trả lời\n",
    "    final_answer = qa_chain.invoke({\n",
    "        \"context\": summary,\n",
    "        \"question\": question\n",
    "    })\n",
    "\n",
    "    return final_answer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bb811fafdf3849c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def db_query(cypher: str, params: Dict[str, Any] = {}) -> pd.DataFrame:\n",
    "    \"\"\"Executes a Cypher statement and returns a DataFrame\"\"\"\n",
    "    return driver.execute_query(\n",
    "        cypher, parameters_=params, result_transformer_=Result.to_df\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98f96fd0ad5402c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MAP_SYSTEM_PROMPT = \"\"\"\n",
    "---Vai trò---\n",
    "\n",
    "Bạn là một trợ lý hữu ích, phản hồi các câu hỏi liên quan đến dữ liệu trong các bảng được cung cấp.\n",
    "\n",
    "\n",
    "---Mục tiêu---\n",
    "\n",
    "Tạo ra một phản hồi gồm danh sách các điểm chính nhằm trả lời câu hỏi của người dùng, tóm tắt tất cả thông tin liên quan trong các bảng dữ liệu đầu vào.\n",
    "\n",
    "Bạn nên sử dụng dữ liệu được cung cấp trong các bảng dữ liệu dưới đây làm bối cảnh chính để tạo phản hồi.\n",
    "Nếu bạn không biết câu trả lời hoặc nếu các bảng dữ liệu đầu vào không chứa đủ thông tin để đưa ra câu trả lời, chỉ cần nói như vậy. Không được bịa ra bất kỳ thông tin nào.\n",
    "\n",
    "Mỗi điểm chính trong phản hồi phải bao gồm các yếu tố sau:\n",
    "- Mô tả: Một mô tả đầy đủ về điểm đó.\n",
    "- Điểm quan trọng: Một số nguyên trong khoảng từ 0-100 thể hiện mức độ quan trọng của điểm đó trong việc trả lời câu hỏi của người dùng. Phản hồi kiểu “Tôi không biết” sẽ có điểm là 0.\n",
    "\n",
    "Phản hồi phải được định dạng JSON như sau:\n",
    "{{\n",
    "    \"points\": [\n",
    "        {{\"description\": \"Mô tả điểm 1 [Dữ liệu: Báo cáo (các mã báo cáo)]\", \"score\": giá_trị_điểm}},\n",
    "        {{\"description\": \"Mô tả điểm 2 [Dữ liệu: Báo cáo (các mã báo cáo)]\", \"score\": giá_trị_điểm}}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "Phản hồi phải giữ nguyên ý nghĩa gốc và cách sử dụng các động từ tình thái như “sẽ”, “có thể” .\n",
    "\n",
    "Các điểm có dữ liệu hỗ trợ nên liệt kê các báo cáo liên quan làm tài liệu tham khảo như sau:\n",
    "\"Đây là một câu ví dụ được hỗ trợ bởi các tài liệu tham khảo [Dữ liệu: Báo cáo (các mã báo cáo)]\"\n",
    "\n",
    "**Không liệt kê nhiều hơn 5 mã báo cáo trong một tài liệu tham khảo**. Thay vào đó, hãy liệt kê 5 mã báo cáo liên quan nhất và thêm “+more” để cho biết còn nhiều hơn nữa.\n",
    "\n",
    "Ví dụ:\n",
    "\"Người X là chủ sở hữu của Công ty Y và bị cáo buộc nhiều sai phạm [Dữ liệu: Báo cáo (2, 7, 64, 46, 34, ...)]. Anh ta cũng là CEO của công ty X [Dữ liệu: Báo cáo (1, 3)]\"\n",
    "\n",
    "trong đó 1, 2, 3, 7, 34, 46, và 64 là mã (không phải chỉ số) của các báo cáo dữ liệu liên quan trong bảng được cung cấp.\n",
    "\n",
    "Không bao gồm thông tin nếu không có bằng chứng hỗ trợ từ dữ liệu.\n",
    "\n",
    "---Các bảng dữ liệu---\n",
    "\n",
    "{context_data}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            MAP_SYSTEM_PROMPT,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "map_chain = map_prompt | llm | StrOutputParser()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71c88c3545053fbb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "REDUCE_SYSTEM_PROMPT = \"\"\"\n",
    "---Vai trò---\n",
    "\n",
    "Bạn là một trợ lý hữu ích, trả lời các câu hỏi về một tập dữ liệu bằng cách tổng hợp các quan điểm từ nhiều nhà phân tích khác nhau.\n",
    "\n",
    "\n",
    "---Mục tiêu---\n",
    "\n",
    "Tạo ra một phản hồi với độ dài và định dạng mục tiêu nhằm trả lời câu hỏi của người dùng, đồng thời tóm tắt tất cả các báo cáo từ nhiều nhà phân tích, mỗi người tập trung vào các phần khác nhau của tập dữ liệu.\n",
    "\n",
    "Lưu ý rằng các báo cáo của nhà phân tích được cung cấp dưới đây **được sắp xếp theo thứ tự quan trọng giảm dần**.\n",
    "\n",
    "Nếu bạn không biết câu trả lời hoặc nếu các báo cáo được cung cấp không chứa đủ thông tin để đưa ra câu trả lời, chỉ cần nói như vậy. Không được bịa ra bất kỳ thông tin nào.\n",
    "\n",
    "Phản hồi cuối cùng nên loại bỏ tất cả thông tin không liên quan từ các báo cáo của nhà phân tích và tổng hợp thông tin đã được làm sạch thành một câu trả lời toàn diện, giải thích tất cả các điểm chính và các hàm ý, phù hợp với độ dài và định dạng của phản hồi.\n",
    "\n",
    "Hãy thêm các phần và bình luận vào phản hồi nếu phù hợp với độ dài và định dạng. Định dạng phản hồi bằng **markdown**.\n",
    "\n",
    "Phản hồi phải giữ nguyên ý nghĩa gốc và cách sử dụng các động từ tình thái như “sẽ”, “có thể”.\n",
    "\n",
    "Phản hồi cũng phải giữ lại tất cả các tham chiếu dữ liệu đã được nêu trong các báo cáo của nhà phân tích, nhưng **không được đề cập đến vai trò của các nhà phân tích trong quá trình phân tích**.\n",
    "\n",
    "**Không liệt kê nhiều hơn 5 mã báo cáo trong một tham chiếu**. Thay vào đó, hãy liệt kê 5 mã báo cáo liên quan nhất và thêm “+more” để chỉ ra rằng còn nhiều hơn nữa.\n",
    "\n",
    "Ví dụ:\n",
    "\n",
    "\"Người X là chủ sở hữu của Công ty Y và bị cáo buộc nhiều sai phạm [Dữ liệu: Báo cáo (2, 7, 34, 46, 64, ...)]. Anh ta cũng là CEO của công ty X [Dữ liệu: Báo cáo (1, 3)]\"\n",
    "\n",
    "trong đó 1, 2, 3, 7, 34, 46 và 64 là mã (không phải chỉ số) của các báo cáo dữ liệu liên quan.\n",
    "\n",
    "Không bao gồm thông tin nếu không có bằng chứng hỗ trợ từ dữ liệu.\n",
    "\n",
    "\n",
    "---Độ dài và định dạng phản hồi mục tiêu---\n",
    "\n",
    "{response_type}\n",
    "\n",
    "\n",
    "---Báo cáo của các nhà phân tích---\n",
    "\n",
    "{report_data}\n",
    "\n",
    "---Độ dài và định dạng phản hồi mục tiêu---\n",
    "\n",
    "{response_type}\n",
    "\n",
    "Hãy thêm các phần và bình luận vào phản hồi nếu phù hợp với độ dài và định dạng. Định dạng phản hồi bằng markdown.\n",
    "\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            REDUCE_SYSTEM_PROMPT,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "reduce_chain = reduce_prompt | llm | StrOutputParser()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd0dd2e8ac9c9570"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "response_type: str = \"nhiều đoạn văn bản\"\n",
    "\n",
    "\n",
    "def global_retriever(query: str, level: int, response_type: str = response_type) -> str:\n",
    "    community_data = graph.query(\n",
    "        \"\"\"\n",
    "    MATCH (c:__Community__)\n",
    "    WHERE c.level = $level\n",
    "    RETURN c.summary AS output\n",
    "    \"\"\",\n",
    "        params={\"level\": level},\n",
    "    )\n",
    "    intermediate_results = []\n",
    "    for community in tqdm(community_data, desc=\"Processing communities\"):\n",
    "        intermediate_response = map_chain.invoke(\n",
    "            {\"question\": query, \"context_data\": community[\"output\"]}\n",
    "        )\n",
    "        intermediate_results.append(intermediate_response)\n",
    "    final_response = reduce_chain.invoke(\n",
    "        {\n",
    "            \"report_data\": intermediate_results,\n",
    "            \"question\": query,\n",
    "            \"response_type\": response_type,\n",
    "        }\n",
    "    )\n",
    "    return final_response"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31a9592e950c4968"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(global_retriever(\"Tóm tắt thông tin về chương trình đào tạo?\", 1))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87c4ed33d8b98d2b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "community_data = graph.query(\n",
    "        \"\"\"\n",
    "    MATCH (c:__Community__)\n",
    "    WHERE c.level = $level\n",
    "        RETURN c.summary AS output\n",
    "    \"\"\",\n",
    "        params={\"level\": 0},\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71f91fa51685af3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for community in tqdm(community_data, desc=\"Processing communities\"):\n",
    "    print(community[\"output\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "876b9aa13a3493cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(global_retriever(\"Tóm tắt thông tin về chương trình đào tạo?\", 0))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e9c6f3eadf74e48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "DETERMINE_QUERY_TYPE_PROMT = \"\"\"\n",
    "Bạn là một trợ lý AI hỗ trợ truy vấn kiến thức từ đồ thị (GraphRAG).\n",
    "Với mỗi câu hỏi tiếng Việt của người dùng, hãy phân tích và cho biết nên sử dụng \"global\" hay \"local\" query để tìm kiếm thông tin.\n",
    "\n",
    "Trả lời duy nhất bằng một từ: \"global\" hoặc \"local\".\n",
    "\n",
    "Với \"global\" là truy vấn được gửi trực tiếp đến toàn bộ các bảng tóm tắt của các cộng đồng trong đồ thị, mà không giới hạn phạm vi tìm kiếm vào một phần nhỏ cụ thể.\n",
    "Mục tiêu: tìm kiếm toàn cục, thường được dùng khi chưa biết rõ ngữ cảnh hoặc muốn lấy thông tin liên quan từ toàn bộ hệ thống kiến thức.\n",
    "Khi nên dùng:\n",
    "Khi truy vấn ban đầu chưa có ngữ cảnh cụ thể.\n",
    "Khi cần xác định vùng liên quan đến truy vấn.\n",
    "Khi muốn thực hiện “zero-shot” truy xuất thông tin từ toàn bộ nguồn kiến thức.\n",
    "\n",
    "Còn \"local\" là truy vấn giới hạn trong một phần con của đồ thị – ví dụ như một neighborhood xung quanh một node cụ thể.\n",
    "Mục tiêu: khai thác cục bộ, tận dụng ngữ cảnh từ một phần cụ thể của đồ thị đã biết trước.\n",
    "Khi nên dùng:\n",
    "Khi đã xác định được “entry point” trong đồ thị (ví dụ: node tương ứng với thực thể người, tổ chức…).\n",
    "Khi chỉ cần truy xuất các thông tin có liên hệ trực tiếp đến node hiện tại.\n",
    "Khi đã có kết quả từ global query và muốn mở rộng hoặc đào sâu ngữ nghĩa từ khu vực đó.\n",
    "\n",
    "Câu hỏi: {question}\n",
    "\"\"\"\n",
    "\n",
    "def determine_query_type(question: str) -> str:\n",
    "    response = llm.invoke([HumanMessage(content=DETERMINE_QUERY_TYPE_PROMT)])\n",
    "    return response.content.strip().lower()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf78a8fc22645b97"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "determine_query_type(\"Tóm tắt thông tin về chương trình đào tạo?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "395209163f9b5ebc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "determine_query_type(\"Điều kiện Đăng ký môn học gồm những gì?\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec54cffff72b1f70"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7fba7c5675800da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bert_score import score as bert_score\n",
    "import string\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Chuẩn hóa văn bản để so sánh exact match.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "def evaluate_qa_response(prediction, ground_truth, lang='en'):\n",
    "    \"\"\"\n",
    "    Đánh giá độ chính xác câu trả lời bằng Exact Match và BERTScore.\n",
    "    \n",
    "    Args:\n",
    "        prediction (str): câu trả lời từ mô hình\n",
    "        ground_truth (str): câu trả lời đúng\n",
    "        lang (str): ngôn ngữ, mặc định là 'en' (hỗ trợ cả 'vi')\n",
    "        \n",
    "    Returns:\n",
    "        dict: {'exact_match': ..., 'bertscore': ...}\n",
    "    \"\"\"\n",
    "    P, R, F1 = bert_score([prediction], [ground_truth], lang=lang, rescale_with_baseline=True)\n",
    "    \n",
    "    return {\n",
    "        'bertscore_precision': round(P[0].item(), 4), # Trung bình độ tương đồng của mỗi token trong câu trả lời mô hình với token gần nhất trong đáp án chuẩn.\n",
    "        'bertscore_recall': round(R[0].item(), 4), # Trung bình độ tương đồng của mỗi token trong đáp án chuẩn với token gần nhất trong câu trả lời mô hình.\n",
    "        'bertscore_f1': round(F1[0].item(), 4) # Trung bình hài hòa giữa Precision và Recall.\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e6c2333573ae7cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ground_truth = \"Sinh viên phải hoàn thành 135 tín chỉ để tốt nghiệp.\"\n",
    "prediction = \"Để tốt nghiệp, sinh viên cần hoàn tất 135 tín chỉ.\"\n",
    "\n",
    "result = evaluate_qa_response(prediction, ground_truth, lang='vi')\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3885b4bfd1268ec3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_promt = \"\"\"\n",
    "Bạn là một giám khảo chuyên đánh giá chất lượng câu trả lời từ hệ thống truy xuất thông tin trong lĩnh vực giáo dục.\n",
    "\n",
    "Dưới đây là một câu hỏi, một câu trả lời từ mô hình, và thông tin tài liệu được truy xuất (nếu có).\n",
    "\n",
    "Hãy đánh giá câu trả lời theo 5 tiêu chí sau:\n",
    "\n",
    "1. Correctness (Câu trả lời có đúng thông tin không?)\n",
    "2. Faithfulness (Câu trả lời có dựa đúng vào tài liệu không?)\n",
    "3. Clarity (Câu trả lời có rõ ràng, dễ hiểu không?)\n",
    "4. Completeness (Câu trả lời có đầy đủ ý không?)\n",
    "5. Usefulness (Câu trả lời có giúp ích cho người hỏi không?)\n",
    "\n",
    "Với mỗi tiêu chí, hãy chấm điểm từ 1 đến 5 và kèm theo nhận xét ngắn.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cee0ab7629978b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_real_answers_from_csv(csv_path: str, output_path: str, chain):\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    real_answers = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            result = chain.invoke({\"question\": row[\"question\"]})\n",
    "\n",
    "            # Xử lý tuỳ vào kiểu object trả về\n",
    "            if hasattr(result, \"content\"):  # nếu là Chat model\n",
    "                real_answers.append(result.content)\n",
    "            elif hasattr(result, \"model_dump_json\"):  # nếu là Pydantic\n",
    "                real_answers.append(result.model_dump_json())\n",
    "            else:\n",
    "                real_answers.append(str(result))\n",
    "\n",
    "        except Exception as e:\n",
    "            real_answers.append(f\"ERROR: {e}\")\n",
    "\n",
    "    df[\"real_answer\"] = real_answers\n",
    "    df.to_csv(output_path, index=False)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26e0f935207ec886"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generate_real_answers_from_csv(\"evaluation_data/Quy_dinh_dao_tao_Thac_si.csv\", \"evaluation_data/out_put_Quy_dinh_dao_tao_Thac_si.csv\", chain)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b693350dc0f030d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_retriever(\"Thời lượng tối thiểu của môn học là bao nhiêu tín chỉ?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b01eda662e6b540"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "real_answers = []\n",
    "result1 = chain.invoke(\"Quy định đào tạo thạc sĩ được ban hành theo quyết định số mấy?\")\n",
    "real_answers.append(result1)\n",
    "print(real_answers)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31caf97c664a2725"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_retriever(\"Điều kiện bảo vệ luận văn là gì?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5ed4c0027389a41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chain.invoke(\"Điều kiện bảo vệ luận văn là gì?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "975de0ee1075b2d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "entity_chain.invoke(\"Điều kiện bảo vệ luận văn là gì?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82cb07090fe98025"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5fb992c6e07ce63c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
